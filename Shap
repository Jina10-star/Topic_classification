import shap
import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import LabelEncoder

# Sample data
texts = [
    "This is a great product",
    "I hate this product",
    "This product is okay",
    "I love this product",
    "This is the worst product",
    "Not bad, could be better",
    "Excellent quality, will buy again",
    "Terrible experience",
    "Just fine, nothing special",
    "Amazing, exceeded expectations"
]
labels = ["positive", "negative", "neutral", "positive", "negative", "neutral", "positive", "negative", "neutral", "positive"]

# Encode labels
label_encoder = LabelEncoder()
encoded_labels = label_encoder.fit_transform(labels)

# Train a simple model
vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(texts)
model = LogisticRegression(multi_class='ovr', max_iter=1000)
model.fit(X, encoded_labels)

# Create a SHAP explainer
explainer = shap.LinearExplainer(model, X, feature_dependence="independent")
shap_values = explainer.shap_values(X)

# Get feature names and SHAP values
feature_names = vectorizer.get_feature_names_out()
shap_values_combined = np.mean(np.abs(shap_values), axis=0)  # Combine SHAP values across classes
shap_values_df = pd.DataFrame(shap_values_combined, columns=feature_names)

# Summarize SHAP values
mean_shap_values = shap_values_df.mean().abs().sort_values(ascending=False)
print("Mean SHAP values for all features:")
print(mean_shap_values)

# Identify stop words
stop_words = set(["this", "is", "a", "the", "i"])  # Example stop words list
stop_words_shap = mean_shap_values[mean_shap_values.index.isin(stop_words)]
print("\nSHAP values for stop words:")
print(stop_words_shap)
